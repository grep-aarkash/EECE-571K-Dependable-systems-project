\section{Approach}
%Here what we propose?
In this paper, we demonstrate cyber-physical attacks on Autonomous Driving systems when some damage is induced in the sensors of the system. We intend to study the effect of tampering the sensors in a subtle manner ( eg. changing temperature, tampering the communication channel between sensor and the control system, introducing malicious packet in the hardware directly controlling the sensor to cause unexpected actvities) on the output of the entire system. This is an unexplored area and the first step in this research involves formulating of attack models for ADS. To detect and mitigate such attacks, we will develop a model-based analysis framework based on the dynamics of the ADS in order to test for any malicious activity.



CARLA will be used as a test platform for development and testing of our approach as it provides a convenient way to instrument and modify the readings of different sensors, as well as the behavior of driver agents that controls the autonomous vehicle. We intend to start our vulnerability analysis, by analyzing the effect on reliability of the system by inducing faults in one of the sensors. This will help in finding out the validity and effectiveness of our approach on a smaller scale so that any adjustment required in our research plan, can be carried out in the initial stages of the project. 

Current approaches that analyze resilience of ADS systems on a holistic level perform fault injections to find vulnerabilities in the system which is quite resource intensive. Details about such approaches is provided in section \ref{related_work}. Our proposed methodology will forgo such ad hoc approaches and test different components of an ADS in a systematic way by modeling its behavior and using formal methods to validate its correctness and finding any unexpected behavior that introduces vulnerabilities in the ADS system. 