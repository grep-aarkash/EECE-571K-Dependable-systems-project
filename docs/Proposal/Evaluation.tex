\section{Evaluation}
In this section we present the fault model for the sensors. We further evaluate the failure rates caused due to the faults in the sensor. We address the following research questions:
\begin{enumerate}
	\item \textbf{RQ1}
	What all types of faults can exist in advanced and core sensors of Autonomous vehicles such as the optical sensor.?
	\item \textbf{RQ2}
	What faults do we consider for the autonomous driving systems?
	\item \textbf{RQ3}
	What subset of the above faults cause the most amount of system damage i.e system failure?
	\item \textbf{RQ4}
	What are the overheads associated with Fault Injection in CARLA?
	
\end{enumerate}
%\vskip 0.1in
We answer the above research questions. 

\vskip 0.1in
\textbf{RQ1: What all types of faults exist in advance and core sensors in an autonomous vehicle.}

There have been lot of studies which look at the individual sensors. These studies also performed an in-depth analysis of the faults which can be present in sensors such as high-powered cameras \cite{5530865}, \cite{inproceedings}. However, none of the previous work categorizes the fault model into hardware faults and data faults as shown in fig. 2. We not only constructed a fault model for the high-powered image sensors, but we chose the faults which are most likely to occur in case of a self driving car. The previous work by Bresolin et al. \cite{inproceedings} performs a fault diagnosis of hybrid systems. However their fault model is limited, as they only consider the hardware faults. 

We chose to start our work with optical sensors because of many reasons. Due to the unstable nature of LIDARs a lot of industrial focus is being shifted towards cameras. A recent work says that soon cheap cameras would replace LIDARs\cite{cheapcamera}. Hence visualization of a 3D world can be constructed using a pair of cameras. In order to do so, it becomes an absolute necessity to understand the faults which can be a part of high-powered cameras as well as low powered cameras. 

As shown in Fig. 2 we consider hardware faults and the data faults. The two major categories we consider in our system for data faults are the image noise and the occlusions. Image noise is the random variation of brightness or color information in images.
The effects of image noises are diverse and can vary from causing minimal damage to the image to
a level which makes it difficult to determine the subject in the image. The different types of image noises can occur due to heating up of the camera and the internal circuits. The image noise can also occur due to temperature variations in the environment. Though there are many existing filters to mitigate these noises, our work is to understand which types of noises despite the numerous filters present cause failure of the system. 

The second types of data faults which we explore are the occlusions. Occlusion means that there is something we want to see, but can't due to some property of our sensor setup or some event. The way of dealing with occlusions varies depending on the way it was caused. If we are developing a system which tracks objects (people, cars, ...) then occlusion occurs if an object you are tracking is hidden (occluded) by another object. Like two persons walking past each other, or a car that drives under a bridge. The problem in this case is what we do when an object disappears and reappears again.

\textbf{RQ2: What faults do we consider for the autonomous driving systems and why?}

In order to validate our hypothesis and compare the failure rates of different faults we limit our experimentation model. Based on our judgment and understanding, we find experimenting with data faults more compelling as compared to hardware faults. One of the major reasons for considering a specific subset of faults are the limitations in our experimental setup CARLA.

\subsection{Limitations of CARLA}
The degree to which CARLA models the real world autonomous driving systems and their interaction with the environment, is dependent on the simulation parameters and driving agents used for controlling the ADS. In real world autonomous driving systems an array of sensors is used, which captures a representation of the environment. This captured data is used by the controller to make driving decisions. CARLA provides the capability to simulate important sensors like cameras  but some important sensors like LIDARs Radar can't be simulated. Moreover the developed driving agents do not incorporate all the sensors available in CARLA. For example, the three driving agents studied by Dosovitskiy et al.~\cite{Dosovitskiy17} do not use LIDAR and rely only on camera output to take driving decisions. Using only camera sensors is not a realistic modeling of real world driving systems currently. Though researchers have been trying to 

There are no open source driving agents currently available that use sensors other than camera so in our study the driving agent we chose also uses only camera sensors. As our focus is on faults in camera sensors, this provides us good insight into reliability of ADS due to these faults. Presence of other sensor in the system may lead to masking of these due to other sensors, which is a more realistic representation of a real world system. Studying the effect sensor faults in presence of other sensors, is the next logical step after studying the reliability of ADS due to individual sensor faults.  

CARLA helped us simulate the optical sensors, in order to understand the failure rates due to image noises and occlusions. We look into different types of occlusions as shows in Fig 2. We test for different noises such as Gaussian noise, salt and pepper noise, speckle noise and Poisson noise. The different types of image noises represent different types of probabilistic faults in an image. For example Gaussian noise distributes the noise uniformly across the entire image. Every image noise has a different probabilistic model. Hence, according to Goodfellow et al.\cite{2014arXiv1412.6572G} we can see that sometimes introducing noise can fool the neural network by giving better results than before. 

We try to understand if all image noises indeed cause the failure of the system. Hence we focus our experimentation in understanding image noise and occlusions.

\textbf{RQ3: What subset of the above faults cause the most amount of system damage i.e System failure?}

\begin{figure}
	\vspace{-0.5em}
	\centering
	\includegraphics[scale=0.7]{success_rate}
	\vspace{-0.5em}
	\caption{Percentage of trials in which ADS was able to complete specified goals in presence of faults.}
	\label{fig:success_rate}
	\vspace{-1.5em}
\end{figure}

\begin{figure}  
	\vspace{1.0em}
	\centering
	\includegraphics[scale=0.7]{no_violations}
	\vspace{-0.5em}
	\caption{Percentage of trials in which ADS was able to complete specified goals, in presence of faults, without committing any traffic violations.}
	\label{fig:no_violations}
	\vspace{-1.5em}
\end{figure}

Figure~\ref{fig:success_rate} shows the success rate of ADS after injection of faults. It can be seen that hardware faults, which are represented as single bit flips in our experiments, do not cause any failures. The output data of image sensor consists of approximately 11.5 million bits, so a single random bit flip event is highly unlikely to cause a perturbation that leads to system failure. Figure~\ref{fig:no_violations} shows the fraction of trials in which the ADS committed any traffic violation, this graph shows that there were no traffic violations when single bit flip faults were injected in the image sensor data. These results validate our approach of focusing on data faults.

For channel occlusion faults, it can be seen that Red channel occlusion leads to highest number of failures as the success rate is only \texttildelow30\%. Green and Blue channel occlusions only result in approximately 10\% decrease in success rate. Similar trends can be seen from Figure~\ref{fig:no_violations} in which Red channel occlusions lead to significantly more traffic violations than other channel occlusions. This shows that the driving agent relies more on red channel then other channels in sensor data. The partial occlusion faults also cause a significant number of failures in the system, with approximately 15\% of trials resulting in failures.

For image noises it can be observed from Figure~\ref{fig:success_rate} and Figure~\ref{fig:no_violations} different noises have varying effects on the success of system behavior. Speckle noise results in the highest number of failures and the success rate in case of speckle noise injection is only \texttildelow40\%. On the other hand injection of Poison noise, results in no failures although Poisson noise causes some traffic violations but none of these violations lead to system failure.

\textbf{RQ4: What are the overheads associated with Fault Injection in CARLA?}

From previous RQ we know that channel occlusion faults and noise addition faults result in most failures of the system so from now on we focus on these faults. For finding the metrics mentioned in Figure~\ref{fig:success_rate} and Figure~\ref{fig:no_violations} we use exhaustive Fault injection. For injecting noise in the sensor data all the pixels in the image have to be updated in every iteration, similarly for channel occlusion faults all the pixels of a particular channel have to be updated in every iteration. The image produced by the camera consist of around 1.4 millions pixels. Updating such a high number values in every iteration of the episode has a huge overhead. Figure~\ref{fig:overhead} shows the average time taken by a single episode of the experiments with and without data fault injections. It can be clearly seen that injecting data faults leads to almost 4 times more time spent in each episode. This overhead and thousands of FI experiments required for exhaustive FI makes this method of FI unscalable. 

\begin{figure}  
	\vspace{1.0em}
	\centering
	\includegraphics[scale=0.7]{overhead}
	\vspace{-0.5em}
	\caption{Average Overhead of injection of data faults in seconds.}
	\label{fig:overhead}
	\vspace{-1.5em}
\end{figure}

We analyzed the failures due to the data faults for any information that can lead to a technique which provides the same coverage as exhaustive FI with less overhead. An interesting fact that emerged from this study was that about 80\% of the failures due to data faults were concentrated near such locations in the environment which were critical. These critical locations include intersections, traffic lights and traffic signs. Figure~\ref{fig:map_critical} shows a subset of these locations on the map that we use for our experiments. We also note that the pattern of parameters of commands, that the controller uses to control the action of the ADS, changes when these critical locations are detected. We combine these two observations to theorize that injecting fault on these locations can lead to all the failures that we observed at these locations during exhaustive fault injections.

Testing the proposed hypothesis reveals that a single data fault injected at critical location does not lead to system failures. We theorize that a single fault is not able to cause large enough deviation in the behavior of ADS to cause a system failure and the Neural network used in the driving agent is able to overcome this fault. With this observation in mind, we injected faults in iterations preceding these critical locations and observed that by increasing the number of iterations in which faults are injected the coverage of FI can be increased, but the drawback is that for the same level of coverage as exhaustive FI, almost same number faults have to be injected which defeats the purpose of the proposed technique.   

\begin{figure}  
	\vspace{1.0em}
	\centering
	\includegraphics[scale=0.7]{map_critical}
	\vspace{-0.5em}
	\caption{Critical locations in our testing environment, at which most failures are observed.}
	\label{fig:map_critical}
	\vspace{-1.5em}
\end{figure}  


